{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Reinforcement Learning\n",
    "Book: \"Introducción al aprendizaje por refuerzo profundo\", Jordi Torres, 2021, Ed. Watch This Space\n",
    "## Part 1, Chapter 2: Formalización del aprendizaje por refuerzo\n",
    "### Frozen Lake: agent following the good plan in a environment with uncertainty (slippery lake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>PRELIMINAR ELEMENTS</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gym library: https://gym.openai.com\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a class Agent that follows the good plan\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.actions = {'left':0, 'down':1, 'right':2, 'up':3}\n",
    "        self.good_plan = 2 * ['down'] + ['right'] + ['down'] + 2 * ['right']\n",
    "        self.step = 0\n",
    "        \n",
    "    def select_action(self):\n",
    "        action = self.good_plan[self.step]\n",
    "        self.step = (self.step + 1) % 6\n",
    "        return self.actions[action]      \n",
    "    \n",
    "    def reset(self):\n",
    "        self.step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>RUNNING THE AGENT FOLLOWING GOOD WAY IN A NON-SLIPPERY ENVIRONMENT</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "\n",
      "Total time steps:  6\n",
      "SOLVED!!!    :)\n"
     ]
    }
   ],
   "source": [
    "# Initialize variable 'agent' with the 'Agent' class\n",
    "agent = Agent()\n",
    "\n",
    "# Creation of environment FrozenLake, from Gym library, with no splippery\n",
    "env = gym.make('FrozenLake-v0', is_slippery = False)\n",
    "\n",
    "# Running and rendering one single episode\n",
    "env.reset()        # reset environment before running episode\n",
    "env.render()       # render the episode\n",
    "is_done = False    # episode completion\n",
    "t = 0              # time step\n",
    " \n",
    "while not is_done:                                   # loop of experiences until episode finishes\n",
    "    action = agent.select_action()                   # passing the decided action\n",
    "    state, reward, is_done, _ = env.step(action)     # interaction with environment acc. to decided action\n",
    "    env.render()                                     # render environment state\n",
    "    t += 1\n",
    "\n",
    "print('\\nTotal time steps: ', t)\n",
    "\n",
    "if state == 15:\n",
    "    print('SOLVED!!!    :)')\n",
    "else:\n",
    "    print('NOT SOLVED  :(')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkblue'>RUNNING THE AGENT IN A SLIPPERY ENVIRONMENT FOR A NUMBER OF EPISODES AND COUNTING SUCCESS RATE</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for running one whole episode\n",
    "def run_episode(agent, env):\n",
    "    env.reset()        # reset environment before running episode\n",
    "    agent.reset()      # reset the agent before running\n",
    "    is_done = False    # episode completion\n",
    "    t = 0              # time step\n",
    "    \n",
    "    while not is_done:                                   # loop of experiences until episode finishes\n",
    "        action = agent.select_action()                   # passing the decided action\n",
    "        state, reward, is_done, _ = env.step(action)     # interaction with environment acc. to decided action\n",
    "        t += 1\n",
    "    return (state, reward, is_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Solved 387 times in 10000 episodes. Success rate: 3.87%\n"
     ]
    }
   ],
   "source": [
    "# Initialize variable 'agent' with the 'Agent' class\n",
    "agent = Agent()\n",
    "\n",
    "# Creation of environment FrozenLake, from Gym library, with splippery condition\n",
    "env = gym.make('FrozenLake-v0', is_slippery = True)\n",
    "\n",
    "n_episodes = 10000   # Definition of number of episode to run\n",
    "\n",
    "solved = 0\n",
    "for episode in range(n_episodes):\n",
    "    state, reward, is_done = run_episode(agent, env)\n",
    "    if state == 15:\n",
    "        solved += 1\n",
    "        \n",
    "print(f'\\n Solved {solved} times in {n_episodes} episodes. Success rate: {solved / n_episodes * 100 :.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
